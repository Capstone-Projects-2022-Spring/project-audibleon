NOTE: CSV data files for training and testing data must be added to project folder manually due to file sizes. 

# Audible ON

***
## Table of Contents
1. [Project Overview](#project-overview)
    * [Our Vision](#our-vision)
    * [Personas and Key Features](#personas-features)
2. [Hello World](#hello-world)
3. [Technologies](#technologies)
4. [New Releases](#new-releases)
    * [How to Download and Install New Release](#download-install-release)
    * [How to Run New Release](#run-release)
5. [Team Contributions](#team-contributions)
    * [Meet Our Team](#team)
    * [Contributions](#contributions)
6. [UML Diagrams](#uml-dia)
    * [Class Diagram](#class-dia)
    * [Sequence Diagram](#seq-dia)
7. [Resources](#resources)
    


***
<a name = "project-overview"></a>
## Project Overview 
Audible ON is an application that utilizes the client’s camera on their device to record and translate gestures from the American Sign Language (ASL) into legible text and/or audible speech, and vice versa (from either text or speech to ASL). Both hearing impaired and non-hearing impaired clients will be able to use this application to communicate with one another in a variety of situations. Audible ON utilizes several other libraries and computing systems such as Google MediaPipe and a Convolutional Neural Network (CNN) to add additional features that will allow user flexibility. Such features will be listed below in the features list.

As technology and medicine advance each year, communication between hearing impaired and non-hearing impaired individuals needs improvement to communicate. Audible ON seeks to allow both groups to communicate with each other without the need for an interpreter. Audible ON’s goal is to allow the hearing impaired to assimilate into society easier by communicating with the general public just as easily as the general public communicates with each other without the need for a live interpreter.


<a name = "our-vision"></a>
### Our Vision

<a name = "personas-features"></a>
### Personas and Key Features

***
<a name = "hello-world"></a>
## ASL Alphabet Detector


### Limitations
* Programmed exclusively for the left hand

***
<a name = "technologies"></a>
## Technologies
* Jupyter Notebook

### Libraries
* Google's MediaPipe
* Keras
* NumPy
* OpenCV
* Time

***
<a name = "new-releases"></a>
## New Releases

<a name = "download-install-release"></a>
### How to Download and Install New Release


<a name = "run-release"></a>
### How to Run New Release
#### Release v0.1.0-alpha:
##### Step 1: Install and run jupyter notebook in a terminal.
##### Step 2: type 'jupyter notebook' in a terminal to run the Jupyter Notebook application.
##### Step 3: Find and select the Tutorial.ipynb file.
##### Step 4: Follow links at the top of Tutorial.ipynb file to ensure proper installation of dependencies (note: this is an important step).
##### Step 5: Run, in sequence, lines 1, 7, 1 (within update config for transfer learning code section), 8, 55, 2 (within load train model from checkpoint code section), 9, and then all of subsequent remaining lines of code.


***
<a name = "team-contributions"></a>
## Team Contributions

<a name = "team"></a>
### Meet Our Team
#### [Shakirah D. Cooper](https://github.com/ArchaePi)
#### [Rachel Lazzaro](https://github.com/rlazz)
#### [Ben Westburg](https://github.com/westbenj2020)
#### [Mahmood Ahmed](https://github.com/RaymondLaubert)
#### [Juan-Carlo Villamor Mercado](https://github.com/JC-127)
#### [Raymond Laubert](https://github.com/MoodAhmed)

<a name = "contributions"></a>
### Contributions

***
<a name = "uml-dia"></a>
## UML Diagrams

<a name = "class-dia"></a>
### Class Diagram

<a name = "seq-dia"></a>
### Sequence Diagram

***

<a name = "resources"></a>
## Resources
https://google.github.io/mediapipe/solutions/hands.html </br>
https://github.com/google/mediapipe/   </br>
***
