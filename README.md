# Audible ON
## Table of Contents
1. [Project Overview](https://github.com/Capstone-Projects-2022-Spring/project-audibleon/edit/main/README.md#project-overview)
2. [Contributors](https://github.com/Capstone-Projects-2022-Spring/project-audibleon/edit/main/README.md#contributors)

### Project Overview
Audible ON is an application that utilizes the client’s camera on their device to record 
and translate gestures from the American Sign Language (ASL) into legible text, as well as speech. Both hearing 
impaired and non-hearing impaired clients will be able to use this application to communicate 
with one another in a variety of situations. Audible ON utilizes several other libraries and 
computing systems such as Google MediaPipe and a Convolutional Neural Network (CNN) to 
add additional features that will allow user flexibility. 

As technology and medicine advance each year, communication between hearing 
impaired and non-hearing impaired individuals needs improvement to communicate. Audible ON 
seeks to allow both groups to communicate with each other without the need for an interpreter. 
Audible ON’s goal is to allow the hearing impaired to assimilate into society easier by 
communicating with the general public just as easily as the general public communicate with 
each other without the need for a live interpreter.

NOTE: CSV data files for training and testing data must be added to project folder manually due to file sizes.

### Contributors
- Ben Westburg
- Juan-Carlo Villamor Mercado 
- Rachel Lazzaro
- Raymond Laubert
- Mahmood Ahmed
- Shakirah Cooper
